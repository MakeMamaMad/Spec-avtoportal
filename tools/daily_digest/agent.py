import os
import json
import random
import html
from pathlib import Path
from datetime import datetime, timezone

import requests
from dateutil import parser as dtparser


# --- ENV ---
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "").strip()
NEWS_JSON_PATH = os.getenv("NEWS_JSON_PATH", "frontend/data/news.json").strip()

# –°–∫–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ (3‚Äì5). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 5.
PICK_N = int(os.getenv("DIGEST_PICK_N", "5"))

# am / pm (–µ—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äî –æ–ø—Ä–µ–¥–µ–ª–∏–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
DIGEST_SLOT = os.getenv("DIGEST_SLOT", "").strip().lower()

STATE_PATH = Path("tools/daily_digest/state.json")
STATE_PATH.parent.mkdir(parents=True, exist_ok=True)

# –ú—è–≥–∫–∏–π –±–∞–Ω-–ª–∏—Å—Ç "–º—É—Å–æ—Ä–∞"
BLOCK_WORDS = ["porsche", "lamborghini", "audi", "–∫—Ä–æ—Å—Å–æ–≤–µ—Ä", "–≤–Ω–µ–¥–æ—Ä–æ–∂–Ω–∏–∫", "iphone", "—Å–º–∞—Ä—Ç—Ñ–æ–Ω"]


# ----------------------------
# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è + "—á—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç"
# ----------------------------
def classify(title: str, url: str = "") -> str:
    t = (title or "").lower()
    u = (url or "").lower()

    if any(k in t for k in ["—à—Ç—Ä–∞—Ñ", "–æ—à—Ç—Ä–∞—Ñ", "–ø—Ä–æ–≤–µ—Ä", "–∫–æ–Ω—Ç—Ä–æ–ª—å", "–∑–∞–∫–æ–Ω", "—Ä–µ–≥–ª–∞–º–µ–Ω—Ç", "–≥–æ—Å—Ç", "—Å–µ—Ä—Ç–∏—Ñ", "–µ–≤—Ä–æ–∫–æ–º–∏—Å—Å", "—Å–∞–Ω–∫—Ü"]):
        return "rules"
    if any(k in t for k in ["—Ü–µ–Ω–∞", "–ø–æ–¥–æ—Ä–æ–∂", "–¥–µ—à–µ–≤", "—Ä—ã–Ω–æ–∫", "—Å–ø—Ä–æ—Å", "–ø—Ä–æ–¥–∞–∂", "–ø–æ—à–ª–∏–Ω", "–∏–Ω—Ñ–ª—è—Ü"]):
        return "market"
    if any(k in t for k in ["–∑–∞–≤–æ–¥", "–≤—ã–ø—É—Å–∫", "–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤", "–ø–æ—Å—Ç–∞–≤–∫–∞", "–¥–µ—Ñ–∏—Ü–∏—Ç", "–ª–æ–≥–∏—Å—Ç–∏–∫", "—Å–∫–ª–∞–¥", "–∏–º–ø–æ—Ä—Ç", "—ç–∫—Å–ø–æ—Ä—Ç"]):
        return "supply"
    if any(k in t for k in ["—Ç—è–≥–∞—á", "–ø–æ–ª—É–ø—Ä–∏—Ü–µ–ø", "–ø—Ä–∏—Ü–µ–ø", "–≥—Ä—É–∑–æ–≤–∏–∫", "—Ñ—É—Ä–∞", "—à–∞—Å—Å–∏", "–æ—Å—å", "—Ç–æ—Ä–º–æ–∑", "–ø–æ–¥–≤–µ—Å–∫", "—à–∏–Ω—ã", "—Ä–µ–º–æ–Ω—Ç", "—Å–µ—Ä–≤–∏—Å"]):
        return "ops"
    if any(k in t for k in ["dhl", "logistics", "–ø–µ—Ä–µ–≤–æ–∑", "—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç", "–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä", "–∏–Ω—Ç–µ—Ä–º–æ–¥–∞–ª", "—Ç–µ—Ä–º–∏–Ω–∞–ª", "–ø–æ—Ä—Ç", "—Å–∫–ª–∞–¥"]):
        return "logistics"

    # –ò–Ω–æ–≥–¥–∞ –ø–æ–ª–µ–∑–Ω–æ –æ—Ç—Å–µ—á—å —Å–æ–≤—Å–µ–º "–Ω–µ –ø—Ä–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç", –Ω–æ —Ç—ã –ø—Ä–æ—Å–∏–ª –≤—Å–µ–≥–¥–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å,
    # –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ—Å—Ç–æ –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ other.
    return "other"


MEANING_BANK = {
    "rules": [
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –≤—ã—à–µ —Ä–∏—Å–∫ –ø—Ä–æ–≤–µ—Ä–æ–∫ –∏ —à—Ç—Ä–∞—Ñ–æ–≤. –î–µ—Ä–∂–∏ –≤ –ø–æ—Ä—è–¥–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Å–≤–µ—Ç/—Ä–∞–∑—ä—ë–º—ã, –∫—Ä–µ–ø—ë–∂ –∏ —É–∑–ª—ã –ø–µ—Ä–µ–¥ —Ä–µ–π—Å–æ–º.",
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –≤–æ–∑–º–æ–∂–Ω—ã –Ω–æ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å —Ç–µ—Ö–Ω–∏–∫—É/–¥–æ–∫—É–º–µ–Ω—Ç—ã –∑–∞—Ä–∞–Ω–µ–µ, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å –ø—Ä–æ—Å—Ç–æ–π.",
    ],
    "market": [
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å—Å—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤–ª–∞–¥–µ–Ω–∏—è. –ï—Å–ª–∏ –ø–ª–∞–Ω–∏—Ä—É–µ—à—å –ø–æ–∫—É–ø–∫—É/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ ‚Äî —Å—Ä–∞–≤–Ω–∏ —Ü–µ–Ω—ã –∏ —É—Å–ª–æ–≤–∏—è, –∑–∞–ª–æ–∂–∏ –∑–∞–ø–∞—Å –ø–æ –±—é–¥–∂–µ—Ç—É.",
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: —Ä—ã–Ω–æ–∫ –∫–∞—á–∞–µ—Ç. –ü—Ä–æ–≤–µ—Ä—å –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ü–µ–Ω—É —Ç–µ—Ö–Ω–∏–∫–∏/–∑–∞–ø—á–∞—Å—Ç–µ–π –∏ —Å—Ä–æ–∫–∏ –ø–æ—Å—Ç–∞–≤–æ–∫.",
    ],
    "supply": [
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –≤–æ–∑–º–æ–∂–Ω—ã —Å–¥–≤–∏–≥–∏ –ø–æ —Å—Ä–æ–∫–∞–º –∏ –Ω–∞–ª–∏—á–∏—é. –ü–ª–∞–Ω–∏—Ä—É–π –∑–∞–∫—É–ø–∫–∏ –∏ —Ä–µ–º–æ–Ω—Ç –∑–∞—Ä–∞–Ω–µ–µ, –æ—Å–æ–±–µ–Ω–Ω–æ —Ä–∞—Å—Ö–æ–¥–Ω–∏–∫–∏.",
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: —Ü–µ–ø–æ—á–∫–∏ –ø–æ—Å—Ç–∞–≤–æ–∫ –º–æ–≥—É—Ç –º–µ–Ω—è—Ç—å—Å—è. –î–µ—Ä–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –ø–æ –±—Ä–µ–Ω–¥–∞–º –∏ —É–∑–ª–∞–º, —É—Ç–æ—á–Ω—è–π —Å—Ä–æ–∫–∏ —É –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤.",
    ],
    "ops": [
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –Ω–∞–ø—Ä—è–º—É—é –ø—Ä–æ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—é. –ü—Ä–æ–≤–µ—Ä—å —É–∑–ª—ã –∏ —Ä–µ–≥–ª–∞–º–µ–Ω—Ç –¢–û, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ø–∞—Å—Ç—å –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π –≤ —Ä–µ–π—Å–µ.",
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: —á–∞—Å—Ç—å –ø—Ä–æ–±–ª–µ–º –º–æ–∂–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏—Ç—å –∑–∞—Ä–∞–Ω–µ–µ. –õ—É—á—à–µ –Ω–∞–π—Ç–∏ —Ä–∏—Å–∫ –¥–æ –≤—ã—Ö–æ–¥–∞ –Ω–∞ –ª–∏–Ω–∏—é.",
    ],
    "logistics": [
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –º–æ–≥—É—Ç –ø–æ–º–µ–Ω—è—Ç—å—Å—è —É—Å–ª–æ–≤–∏—è –ø–µ—Ä–µ–≤–æ–∑–æ–∫/–º–∞—Ä—à—Ä—É—Ç–æ–≤. –≠—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ —Å—Ä–æ–∫–∏ –∏ —Ä–∞—Å—Ö–æ–¥—ã –Ω–∞ —Ä–µ–π—Å.",
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –≤–æ–∑–º–æ–∂–Ω–∞ –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Å—Ç–∏–∫–∏. –î–µ—Ä–∂–∏ –≤ —É–º–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã –∏ –æ–∫–Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∏.",
    ],
    "other": [
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –Ω–æ–≤–æ—Å—Ç—å —Å–º–µ–∂–Ω–∞—è. –û—Ü–µ–Ω–∏ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –ø–µ—Ä–µ–≤–æ–∑–∫–∏/—Ä—ã–Ω–æ–∫ —Ç–µ—Ö–Ω–∏–∫–∏, –∏–Ω–∞—á–µ –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å.",
        "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –≤–ª–∏—è–Ω–∏–µ –Ω–µ–æ—á–µ–≤–∏–¥–Ω–æ. –°–º–æ—Ç—Ä–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç, –ª–æ–≥–∏—Å—Ç–∏–∫—É –∏–ª–∏ —Ä—ã–Ω–æ–∫ —Ç–µ—Ö–Ω–∏–∫–∏.",
    ],
}


def meaning_for(title: str, url: str = "") -> str:
    c = classify(title, url)
    return random.choice(MEANING_BANK.get(c, MEANING_BANK["other"]))


# ----------------------------
# State / helpers
# ----------------------------
def get_slot_utc() -> str:
    """–ê–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ—Ç–∞ –ø–æ UTC. –î–æ 12:00 UTC = am, –ø–æ—Å–ª–µ = pm."""
    hour = datetime.now(timezone.utc).hour
    return "am" if hour < 12 else "pm"


def load_state() -> dict:
    if STATE_PATH.exists():
        try:
            s = json.loads(STATE_PATH.read_text(encoding="utf-8"))
        except Exception:
            s = {}
    else:
        s = {}

    s.setdefault("used_urls", [])
    # {"YYYY-MM-DD": {"am": true, "pm": true}}
    s.setdefault("last_post", {})
    return s


def save_state(state: dict) -> None:
    STATE_PATH.write_text(json.dumps(state, ensure_ascii=False, indent=2), encoding="utf-8")


def read_news() -> list[dict]:
    p = Path(NEWS_JSON_PATH)
    if not p.exists():
        raise RuntimeError(f"news json not found: {NEWS_JSON_PATH}")
    data = json.loads(p.read_text(encoding="utf-8"))
    if not isinstance(data, list):
        raise RuntimeError("news.json must be a list")
    return data


def extract_url(item: dict) -> str:
    for k in ("url", "link", "href", "source_url"):
        v = item.get(k)
        if isinstance(v, str) and v.startswith("http"):
            return v.strip()
    return ""


def with_utm(url: str) -> str:
    if not url:
        return url
    if "utm_" in url:
        return url
    sep = "&" if "?" in url else "?"
    return f"{url}{sep}utm_source=telegram&utm_medium=digest&utm_campaign=daily"


def extract_title(item: dict) -> str:
    for k in ("title", "headline", "name"):
        v = item.get(k)
        if isinstance(v, str) and v.strip():
            return v.strip()
    return ""


def extract_date(item: dict):
    """–ù–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ –ø—É—Å—Ç—å –±—É–¥–µ—Ç –Ω–∞ –±—É–¥—É—â–µ–µ."""
    for k in ("published_at", "published", "date", "datetime", "time", "ts"):
        v = item.get(k)
        if not v:
            continue
        try:
            if isinstance(v, (int, float)):
                return datetime.fromtimestamp(float(v), tz=timezone.utc)
            if isinstance(v, str):
                d = dtparser.parse(v)
                if d.tzinfo is None:
                    d = d.replace(tzinfo=timezone.utc)
                return d
        except Exception:
            continue
    return None


def esc_html(s: str) -> str:
    return html.escape(s or "", quote=False)


# ----------------------------
# Picking (always 3‚Äì5, no topic)
# ----------------------------
def pick_items(news: list[dict], used_urls: set[str]) -> list[dict]:
    """
    –í—Å–µ–≥–¥–∞ —Å—Ç–∞—Ä–∞–µ–º—Å—è –≤—ã–±—Ä–∞—Ç—å PICK_N –Ω–æ–≤–æ—Å—Ç–µ–π –±–µ–∑ —Ç–µ–º—ã.
    1) –°–Ω–∞—á–∞–ª–∞ –±–µ—Ä—ë–º "–Ω–æ–≤—ã–µ" (–Ω–µ –≤ used_urls) –∏ –Ω–µ –∏–∑ BLOCK_WORDS
    2) –ï—Å–ª–∏ —Ç–∞–∫–∏—Ö < 3 ‚Äî —Ä–∞–∑—Ä–µ—à–∞–µ–º –ø–æ–≤—Ç–æ—Ä (–∏–Ω–∞—á–µ –∫–∞–Ω–∞–ª —É–º—Ä—ë—Ç), –Ω–æ –≤—Å—ë —Ä–∞–≤–Ω–æ –±–∞–Ω–∏–º BLOCK_WORDS
    """
    candidates: list[dict] = []

    for it in news:
        if not isinstance(it, dict):
            continue
        url = extract_url(it)
        title = extract_title(it)
        if not url or not title:
            continue

        title_l = title.lower()
        if any(w in title_l for w in BLOCK_WORDS):
            continue

        if url in used_urls:
            continue

        candidates.append(it)

    # –ï—Å–ª–∏ –≤—Å—ë "—Å—ä–µ–¥–µ–Ω–æ" used_urls ‚Äî —Ä–∞–∑—Ä–µ—à–∞–µ–º –ø–æ–≤—Ç–æ—Ä, –Ω–æ –±–µ–∑ –º—É—Å–æ—Ä–∞
    if len(candidates) < 3:
        candidates = []
        for it in news:
            if not isinstance(it, dict):
                continue
            url = extract_url(it)
            title = extract_title(it)
            if not url or not title:
                continue

            title_l = title.lower()
            if any(w in title_l for w in BLOCK_WORDS):
                continue

            candidates.append(it)

    if not candidates:
        return []

    n = min(PICK_N, len(candidates))

    if len(candidates) <= n:
        return candidates

    return random.sample(candidates, n)


# ----------------------------
# Digest formatting (grouped)
# ----------------------------
def make_digest_post(items: list[dict], slot: str) -> str:
    today = datetime.now().strftime("%d.%m.%Y")
    header = (
        f"üöõ <b>{'–£—Ç—Ä–µ–Ω–Ω—è—è' if slot=='am' else '–í–µ—á–µ—Ä–Ω—è—è'} —Å–≤–æ–¥–∫–∞ ‚Äî {today}</b>\n"
        f"<i>{len(items)} –Ω–æ–≤–æ—Å—Ç–µ–π + –∫–æ—Ä–æ—Ç–∫–∏–π –≤—ã–≤–æ–¥ –ø–æ –∫–∞–∂–¥–æ–π</i>\n"
    )

    groups = {"rules": [], "market": [], "supply": [], "ops": [], "logistics": [], "other": []}
    for it in items:
        title = extract_title(it)
        url = with_utm(extract_url(it))
        c = classify(title, url)
        groups[c].append((title, url))

    order = [
        ("rules", "‚ö†Ô∏è –ö–æ–Ω—Ç—Ä–æ–ª—å / –ø—Ä–∞–≤–∏–ª–∞"),
        ("market", "üìà –†—ã–Ω–æ–∫ / —Ü–µ–Ω—ã"),
        ("supply", "üöö –ü–æ—Å—Ç–∞–≤–∫–∏ / –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ"),
        ("ops", "üîß –≠–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è / —Ç–µ—Ö–Ω–∏–∫–∞"),
        ("logistics", "üì¶ –õ–æ–≥–∏—Å—Ç–∏–∫–∞"),
        ("other", "üß© –û—Å—Ç–∞–ª—å–Ω–æ–µ"),
    ]

    lines = [header]
    n = 0

    for key, label in order:
        if not groups[key]:
            continue
        lines.append(f"\n<b>{label}</b>")
        for title, url in groups[key]:
            n += 1
            m = meaning_for(title, url)
            lines.append(f"{n}Ô∏è‚É£ <b>{esc_html(title)}</b>")
            lines.append(esc_html(m))
            lines.append(f"üîó {url}")

    lines.append("\nüìå <b>–°–∞–π—Ç</b> ‚Äî –∞—Ä—Ö–∏–≤ –∏ –ø–æ–¥–±–æ—Ä–∫–∞. <b>TG</b> ‚Äî 2 —Å–≤–æ–¥–∫–∏ –≤ –¥–µ–Ω—å + –ª–µ–Ω—Ç–∞ –Ω–æ–≤–æ—Å—Ç–µ–π.")
    return "\n".join(lines).strip()


# ----------------------------
# Telegram send
# ----------------------------
def tg_send(text: str) -> None:
    if not BOT_TOKEN or not CHAT_ID:
        raise RuntimeError("Missing TELEGRAM_BOT_TOKEN or TELEGRAM_CHAT_ID")

    api = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": False,
    }
    r = requests.post(api, json=payload, timeout=30)

    try:
        j = r.json()
    except Exception:
        j = {"raw": r.text}

    print("Telegram status:", r.status_code)
    print("Telegram response:", j)

    r.raise_for_status()
    if not j.get("ok"):
        raise RuntimeError(f"Telegram API error: {j}")


# ----------------------------
# Main
# ----------------------------
def main():
    state = load_state()

    today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    slot = DIGEST_SLOT if DIGEST_SLOT in ("am", "pm") else get_slot_utc()

    posted_today = state.get("last_post", {}).get(today, {})
    if posted_today.get(slot):
        print(f"Digest already posted today for slot={slot}. Exit.")
        return

    used = set(state.get("used_urls", []))
    news = read_news()
    picked = pick_items(news, used)

    if not picked:
        print("No suitable items found. Exit.")
        return

    if len(picked) < 3:
        print(f"Too few items for digest: {len(picked)}. Exit.")
        return

    post = make_digest_post(picked, slot)
    tg_send(post)

    # –æ–±–Ω–æ–≤–ª—è–µ–º used_urls
    for it in picked:
        u = extract_url(it)
        if u:
            used.add(u)

    state["used_urls"] = list(used)[-800:]  # —á—É—Ç—å –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏

    # –æ—Ç–º–µ—á–∞–µ–º —Å–ª–æ—Ç
    state.setdefault("last_post", {})
    state["last_post"].setdefault(today, {})
    state["last_post"][today][slot] = True

    # —á–∏—Å—Ç–∏–º –∏—Å—Ç–æ—Ä–∏—é last_post –¥–æ 14 –¥–Ω–µ–π
    days = sorted(state["last_post"].keys())
    if len(days) > 14:
        for d in days[:-14]:
            state["last_post"].pop(d, None)

    save_state(state)
    print(f"OK: digest posted. slot={slot}")


if __name__ == "__main__":
    main()
