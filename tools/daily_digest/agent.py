import os
import json
import random
import html
from pathlib import Path
from datetime import datetime, timedelta, timezone

import requests
from dateutil import parser as dtparser


# --- ENV ---
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "").strip()
NEWS_JSON_PATH = os.getenv("NEWS_JSON_PATH", "frontend/data/news.json").strip()

PICK_N = int(os.getenv("DIGEST_PICK_N", "5"))
LOOKBACK_HOURS = int(os.getenv("LOOKBACK_HOURS", "48"))

# am / pm (–µ—Å–ª–∏ –ø—É—Å—Ç–æ ‚Äî –æ–ø—Ä–µ–¥–µ–ª–∏–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
DIGEST_SLOT = os.getenv("DIGEST_SLOT", "").strip().lower()

STATE_PATH = Path("tools/daily_digest/state.json")
STATE_PATH.parent.mkdir(parents=True, exist_ok=True)

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ ‚Äú—Å—Ç—Ä–æ–≥–æ —Ç—è–≥–∞—á–∏/–ø–æ–ª—É–ø—Ä–∏—Ü–µ–ø—ã‚Äù
TOPIC_WORDS = [
    "–ø–æ–ª—É–ø—Ä–∏—Ü–µ–ø", "–ø–æ–ª—É–ø—Ä–∏—Ü–µ–ø—ã", "–ø—Ä–∏—Ü–µ–ø", "–ø—Ä–∏—Ü–µ–ø—ã", "—Ç—è–≥–∞—á", "—Ç—è–≥–∞—á–∏",
    "—Å–µ–¥–µ–ª—å–Ω—ã–π", "—Å–µ–¥–µ–ª—å–Ω—ã–µ",
    "trailer", "trailers", "semi", "semi-trailer", "tractor trailer", "articulated",
]


def get_slot_utc() -> str:
    """–ê–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ—Ç–∞ –ø–æ UTC. –î–æ 12:00 UTC = am, –ø–æ—Å–ª–µ = pm."""
    hour = datetime.now(timezone.utc).hour
    return "am" if hour < 12 else "pm"


def load_state() -> dict:
    if STATE_PATH.exists():
        try:
            s = json.loads(STATE_PATH.read_text(encoding="utf-8"))
        except Exception:
            s = {}
    else:
        s = {}

    s.setdefault("used_urls", [])
    # {"YYYY-MM-DD": {"am": true, "pm": true}}
    s.setdefault("last_post", {})
    return s


def save_state(state: dict) -> None:
    STATE_PATH.write_text(json.dumps(state, ensure_ascii=False, indent=2), encoding="utf-8")


def read_news() -> list[dict]:
    p = Path(NEWS_JSON_PATH)
    if not p.exists():
        raise RuntimeError(f"news json not found: {NEWS_JSON_PATH}")
    data = json.loads(p.read_text(encoding="utf-8"))
    if not isinstance(data, list):
        raise RuntimeError("news.json must be a list")
    return data


def extract_url(item: dict) -> str:
    for k in ("url", "link", "href", "source_url"):
        v = item.get(k)
        if isinstance(v, str) and v.startswith("http"):
            return v.strip()
    return ""


def with_utm(url: str) -> str:
    if not url:
        return url
    if "utm_" in url:
        return url
    sep = "&" if "?" in url else "?"
    return f"{url}{sep}utm_source=telegram&utm_medium=digest&utm_campaign=daily"


def extract_title(item: dict) -> str:
    for k in ("title", "headline", "name"):
        v = item.get(k)
        if isinstance(v, str) and v.strip():
            return v.strip()
    return ""


def extract_date(item: dict) -> datetime | None:
    for k in ("published_at", "published", "date", "datetime", "time", "ts"):
        v = item.get(k)
        if not v:
            continue
        try:
            if isinstance(v, (int, float)):
                return datetime.fromtimestamp(float(v), tz=timezone.utc)
            if isinstance(v, str):
                d = dtparser.parse(v)
                if d.tzinfo is None:
                    d = d.replace(tzinfo=timezone.utc)
                return d
        except Exception:
            continue
    return None


def is_on_topic(item: dict) -> bool:
    title = extract_title(item).lower()
    if any(w in title for w in TOPIC_WORDS):
        return True

    tags = item.get("tags") or item.get("categories")
    if isinstance(tags, list):
        joined = " ".join([str(x).lower() for x in tags])
        if any(w in joined for w in TOPIC_WORDS):
            return True

    return False



def pick_items(news: list[dict], used_urls: set[str]) -> list[dict]:
    now = datetime.now(timezone.utc)
    cutoff = now - timedelta(hours=LOOKBACK_HOURS)

    fresh: list[tuple[int, dict]] = []
    for it in news:
        if not isinstance(it, dict):
            continue

        url = extract_url(it)
        title = extract_title(it)
        if not url or not title:
            continue

        if url in used_urls:
            continue

        if not is_on_topic(it):
            continue

        d = extract_date(it)
        score = 0
        if d:
            if d < cutoff:
                continue
            age_hours = (now - d).total_seconds() / 3600
            score = max(0, int(100 - age_hours))
        else:
            # –µ—Å–ª–∏ –¥–∞—Ç—ã –Ω–µ—Ç ‚Äî –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –Ω–æ –¥–æ–ø—É—Å–∫–∞–µ–º
            score = 10

        fresh.append((score, it))

    fresh.sort(key=lambda x: x[0], reverse=True)

    # –±–µ—Ä—ë–º –≤–µ—Ä—Ö–Ω—é—é —á–∞—Å—Ç—å –ø–æ ‚Äú–Ω–æ–≤–∏–∑–Ω–µ‚Äù, –∞ –≤—ã–±–æ—Ä –≤–Ω—É—Ç—Ä–∏ –¥–µ–ª–∞–µ–º —Ä–∞–Ω–¥–æ–º–æ–º
    top_pool = [it for _, it in fresh[: max(20, PICK_N * 4)]]

    if len(top_pool) <= PICK_N:
        return top_pool

    return random.sample(top_pool, PICK_N)


def esc_html(s: str) -> str:
    return html.escape(s, quote=False)


def meaning_for(title: str) -> str:
    t = (title or "").lower()

    if any(k in t for k in ["–¥–µ—à–µ–≤", "–ø–æ–¥–æ—Ä–æ–∂", "—Ü–µ–Ω–∞", "—Å—Ç–æ–∏–º–æ—Å—Ç", "—Ä—ã–Ω–æ–∫", "–ø—Ä–æ–¥–∞–∂", "—Å–ø—Ä–æ—Å"]):
        return ("–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –≤–æ–∑–º–æ–∂–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω –Ω–∞ —Ç–µ—Ö–Ω–∏–∫—É –∏ –∑–∞–ø—á–∞—Å—Ç–∏. "
                "–ï—Å–ª–∏ –ø–ª–∞–Ω–∏—Ä—É–µ—à—å –ø–æ–∫—É–ø–∫—É/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ ‚Äî —Å—Ä–∞–≤–Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ —Å—Ä–æ–∫–∏ –ø–æ—Å—Ç–∞–≤–æ–∫.")

    if any(k in t for k in ["–≤—ã–ø—É—Å–∫", "–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤", "–∑–∞–≤–æ–¥", "—Å–æ–∫—Ä–∞—Ç", "—Ä–æ—Å—Ç –≤—ã–ø—É—Å–∫", "—Å–µ—Ä–∏—è"]):
        return ("–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –º–æ–≥—É—Ç –º–µ–Ω—è—Ç—å—Å—è —Å—Ä–æ–∫–∏ –ø–æ—Å—Ç–∞–≤–æ–∫ –∏ –Ω–∞–ª–∏—á–∏–µ. "
                "–ü–ª–∞–Ω–∏—Ä—É–π –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∫–∞ –∏ –∑–∞–∫–∞–∑—ã –∑–∞—Ä–∞–Ω–µ–µ.")

    if any(k in t for k in ["–ø—Ä–µ–¥—Å—Ç–∞–≤", "–ø—Ä–µ–∑–µ–Ω—Ç", "–Ω–æ–≤–∏–Ω–∫", "–º–æ–¥–µ–ª—å", "–≤—ã—Å—Ç–∞–≤–∫", "—Ñ–æ—Ä—É–º"]):
        return ("–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –ø–æ—è–≤–ª—è—é—Ç—Å—è –Ω–æ–≤—ã–µ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏ –∏ —Ä–µ—à–µ–Ω–∏—è. "
                "–ü—Ä–æ–≤–µ—Ä—å, –µ—Å—Ç—å –ª–∏ –≤—ã–≥–æ–¥–∞ –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –≤–ª–∞–¥–µ–Ω–∏—è –∏ —Å–µ—Ä–≤–∏—Å—É.")

    if any(k in t for k in ["—à—Ç—Ä–∞—Ñ", "–∫–æ–Ω—Ç—Ä–æ–ª—å", "–∏–Ω—Å–ø–µ–∫—Ü", "—Ç—Ä–µ–±–æ–≤–∞–Ω", "–∑–∞–∫–æ–Ω", "–ø—Ä–∞–≤–∏–ª", "—Å–µ—Ä—Ç–∏—Ñ"]):
        return ("–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –ø–æ–≤—ã—à–∞–µ—Ç—Å—è —Ä–∏—Å–∫ —à—Ç—Ä–∞—Ñ–æ–≤ –∏ –ø—Ä–æ—Å—Ç–æ–µ–≤. "
                "–ü—Ä–æ–≤–µ—Ä—å –¥–æ–∫—É–º–µ–Ω—Ç—ã, –∫—Ä–µ–ø—ë–∂, —Å–≤–µ—Ç/—Ä–∞–∑—ä—ë–º—ã –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —É–∑–ª–æ–≤ –ø–µ—Ä–µ–¥ —Ä–µ–π—Å–æ–º.")

    if any(k in t for k in ["—Ä–µ–º–æ–Ω—Ç", "—Å–µ—Ä–≤–∏—Å", "–ø–æ–ª–æ–º–∫", "–Ω–µ–∏—Å–ø—Ä–∞–≤", "—Ç–æ—Ä–º–æ–∑", "–æ—Å—å", "–ø–æ–¥–≤–µ—Å–∫", "—à–∏–Ω—ã"]):
        return ("–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –æ–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ —É–∑–ª–æ–≤. "
                "–ü—Ä–æ–±–ª–µ–º—É –¥–µ—à–µ–≤–ª–µ –ø–æ–π–º–∞—Ç—å –∑–∞—Ä–∞–Ω–µ–µ, —á–µ–º –ª–æ–≤–∏—Ç—å –ø—Ä–æ—Å—Ç–æ–π –Ω–∞ –ª–∏–Ω–∏–∏.")

    return "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –¥–µ—Ä–∂–∏ –≤ —Ñ–æ–∫—É—Å–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—é, —Å—Ä–æ–∫–∏ –∏ –∑–∞—Ç—Ä–∞—Ç—ã. –°—Å—ã–ª–∫–∏ –∏ –¥–µ—Ç–∞–ª–∏ ‚Äî –Ω–∏–∂–µ."


def make_digest_post(items: list[dict], slot: str) -> str:
    today = datetime.now().strftime("%d.%m.%Y")

    if slot == "am":
        header = f"üöõ <b>–£—Ç—Ä–µ–Ω–Ω—è—è —Å–≤–æ–¥–∫–∞ –ø–æ —Ç—è–≥–∞—á–∞–º –∏ –ø–æ–ª—É–ø—Ä–∏—Ü–µ–ø–∞–º ‚Äî {today}</b>"
        footer = "üìå –£—Ç—Ä–æ: —Å–æ–±—Ä–∞–ª–∏ –≥–ª–∞–≤–Ω–æ–µ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã. –í–µ—á–µ—Ä–æ–º ‚Äî –∏—Ç–æ–≥–∏ –¥–Ω—è."
    else:
        header = f"üöõ <b>–í–µ—á–µ—Ä–Ω—è—è —Å–≤–æ–¥–∫–∞ –ø–æ —Ç—è–≥–∞—á–∞–º –∏ –ø–æ–ª—É–ø—Ä–∏—Ü–µ–ø–∞–º ‚Äî {today}</b>"
        footer = "üìå –í–µ—á–µ—Ä: –∏—Ç–æ–≥–∏ –¥–Ω—è"

    lines = [header, ""]

    for i, it in enumerate(items, 1):
        raw_title = extract_title(it)
        title = esc_html(raw_title)
        url = with_utm(extract_url(it))
        meaning = meaning_for(raw_title)

        lines.append(f"{i}Ô∏è‚É£ <b>{title}</b>")
        lines.append(esc_html(meaning))
        lines.append(f"üîó {url}")
        lines.append("")

    lines.append(footer)
    return "\n".join(lines).strip()


def tg_send(text: str) -> None:
    if not BOT_TOKEN or not CHAT_ID:
        raise RuntimeError("Missing TELEGRAM_BOT_TOKEN or TELEGRAM_CHAT_ID")

    api = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": False,
    }
    r = requests.post(api, json=payload, timeout=30)

    # –Ω–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–æ–∫ ‚Äî –ø–æ–∫–∞–∂–µ–º –æ—Ç–≤–µ—Ç
    try:
        j = r.json()
    except Exception:
        j = {"raw": r.text}

    print("Telegram status:", r.status_code)
    print("Telegram response:", j)

    r.raise_for_status()
    if not j.get("ok"):
        raise RuntimeError(f"Telegram API error: {j}")


def main():
    state = load_state()

    today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    slot = DIGEST_SLOT if DIGEST_SLOT in ("am", "pm") else get_slot_utc()

    posted_today = state.get("last_post", {}).get(today, {})
    if posted_today.get(slot):
        print(f"Digest already posted today for slot={slot}. Exit.")
        return

    used = set(state.get("used_urls", []))
    news = read_news()
    picked = pick_items(news, used)

    if not picked:
        print("No suitable items found (topic/freshness/duplicates). Exit.")
        return

    # –º–∏–Ω–∏–º—É–º 3 –ø—É–Ω–∫—Ç–∞, –∏–Ω–∞—á–µ –Ω–µ –ø–æ—Å—Ç–∏–º ‚Äú–ø—É—Å—Ç—É—é‚Äù —Å–≤–æ–¥–∫—É
    if len(picked) < 3:
        print(f"Too few items for digest: {len(picked)}. Exit.")
        return

    post = make_digest_post(picked, slot)
    tg_send(post)

    # –æ–±–Ω–æ–≤–ª—è–µ–º used_urls
    for it in picked:
        u = extract_url(it)
        if u:
            used.add(u)

    state["used_urls"] = list(used)[-500:]

    # –æ—Ç–º–µ—á–∞–µ–º —Å–ª–æ—Ç
    state.setdefault("last_post", {})
    state["last_post"].setdefault(today, {})
    state["last_post"][today][slot] = True

    # —á–∏—Å—Ç–∏–º –∏—Å—Ç–æ—Ä–∏—é last_post –¥–æ 14 –¥–Ω–µ–π
    days = sorted(state["last_post"].keys())
    if len(days) > 14:
        for d in days[:-14]:
            state["last_post"].pop(d, None)

    save_state(state)
    print(f"OK: digest posted. slot={slot}")


if __name__ == "__main__":
    main()
