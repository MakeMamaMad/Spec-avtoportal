import os
import json    
import random
import re
import html
from pathlib import Path
from datetime import datetime, timedelta, timezone

import requests
from dateutil import parser as dtparser


BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "").strip()
NEWS_JSON_PATH = os.getenv("NEWS_JSON_PATH", "frontend/data/news.json").strip()
PICK_N = int(os.getenv("DIGEST_PICK_N", "6"))

STATE_PATH = Path("tools/daily_digest/state.json")
STATE_PATH.parent.mkdir(parents=True, exist_ok=True)

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ ‚Äú—Å—Ç—Ä–æ–≥–æ —Ç—è–≥–∞—á–∏/–ø–æ–ª—É–ø—Ä–∏—Ü–µ–ø—ã‚Äù
TOPIC_WORDS = [
    "–ø–æ–ª—É–ø—Ä–∏—Ü–µ–ø", "–ø–æ–ª—É–ø—Ä–∏—Ü–µ–ø—ã", "–ø—Ä–∏—Ü–µ–ø", "–ø—Ä–∏—Ü–µ–ø—ã", "—Ç—è–≥–∞—á", "—Ç—è–≥–∞—á–∏",
    "—Å–µ–¥–µ–ª—å–Ω—ã–π", "—Å–µ–¥–µ–ª—å–Ω—ã–µ",
    "trailer", "trailers", "semi", "semi-trailer", "tractor trailer", "articulated",
]

def load_state():
    if STATE_PATH.exists():
        try:
            return json.loads(STATE_PATH.read_text(encoding="utf-8"))
        except Exception:
            pass
    return {"used_urls": [], "last_post_date": ""}

def save_state(state):
    STATE_PATH.write_text(json.dumps(state, ensure_ascii=False, indent=2), encoding="utf-8")

def read_news():
    p = Path(NEWS_JSON_PATH)
    if not p.exists():
        raise RuntimeError(f"news json not found: {NEWS_JSON_PATH}")
    data = json.loads(p.read_text(encoding="utf-8"))
    if not isinstance(data, list):
        raise RuntimeError("news.json must be a list")
    return data

def extract_url(item: dict) -> str:
    for k in ("url", "link", "href", "source_url"):
        v = item.get(k)
        if isinstance(v, str) and v.startswith("http"):
            return v.strip()
    return ""
def with_utm(url: str) -> str:
    if "utm_" in url:
        return url
    sep = "&" if "?" in url else "?"
    return f"{url}{sep}utm_source=telegram&utm_medium=digest&utm_campaign=daily"


def extract_title(item: dict) -> str:
    for k in ("title", "headline", "name"):
        v = item.get(k)
        if isinstance(v, str) and v.strip():
            return v.strip()
    return ""

def extract_date(item: dict) -> datetime | None:
    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –¥–∞—Ç—É –≤ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø–æ–ª—è—Ö
    for k in ("published_at", "published", "date", "datetime", "time", "ts"):
        v = item.get(k)
        if not v:
            continue
        try:
            if isinstance(v, (int, float)):
                # –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º unix seconds
                return datetime.fromtimestamp(float(v), tz=timezone.utc)
            if isinstance(v, str):
                d = dtparser.parse(v)
                if d.tzinfo is None:
                    d = d.replace(tzinfo=timezone.utc)
                return d
        except Exception:
            continue
    return None

def is_on_topic(item: dict) -> bool:
    title = extract_title(item).lower()
    if any(w in title for w in TOPIC_WORDS):
        return True
    # –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–≥–∏/–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚Äî —Ç–æ–∂–µ —É—á–∏—Ç—ã–≤–∞–µ–º
    tags = item.get("tags") or item.get("categories")
    if isinstance(tags, list):
        joined = " ".join([str(x).lower() for x in tags])
        if any(w in joined for w in TOPIC_WORDS):
            return True
    return False

def pick_items(news: list[dict], used_urls: set[str]) -> list[dict]:
    # —Å–≤–µ–∂–µ—Å—Ç—å: –ø–æ—Å–ª–µ–¥–Ω–∏–µ 48 —á–∞—Å–æ–≤ (–º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å)
    now = datetime.now(timezone.utc)
    cutoff = now - timedelta(hours=48)

    fresh = []
    for it in news:
        if not isinstance(it, dict):
            continue
        url = extract_url(it)
        title = extract_title(it)
        if not url or not title:
            continue
        if url in used_urls:
            continue
        if not is_on_topic(it):
            continue

        d = extract_date(it)
        # –µ—Å–ª–∏ –¥–∞—Ç—ã –Ω–µ—Ç ‚Äî –≤—Å—ë —Ä–∞–≤–Ω–æ –º–æ–∂–Ω–æ –≤–∑—è—Ç—å, –Ω–æ –ª—É—á—à–µ –Ω–∏–∂–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        score = 0
        if d:
            if d < cutoff:
                continue
            # —á–µ–º –Ω–æ–≤–µ–µ ‚Äî —Ç–µ–º –≤—ã—à–µ —à–∞–Ω—Å –ø–æ–ø–∞—Å—Ç—å
            age_hours = (now - d).total_seconds() / 3600
            score = max(0, int(100 - age_hours))
        else:
            score = 10

        fresh.append((score, it))

    # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ ‚Äú–Ω–æ–≤–∏–∑–Ω–µ‚Äù, –Ω–æ –≤—ã–±–∏—Ä–∞–µ–º —Ä–∞–Ω–¥–æ–º–æ–º –∏–∑ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏
    fresh.sort(key=lambda x: x[0], reverse=True)
    top_pool = [it for _, it in fresh[: max(20, PICK_N * 4)]]

    if len(top_pool) <= PICK_N:
        return top_pool

    return random.sample(top_pool, PICK_N)

def esc_html(s: str) -> str:
    return html.escape(s, quote=False)

def make_digest_post(items: list[dict]) -> str:
    today = datetime.now().strftime("%d.%m.%Y")
    lines = [f"üöõ <b>–ì–ª–∞–≤–Ω–æ–µ –ø–æ —Ç—è–≥–∞—á–∞–º –∏ –ø–æ–ª—É–ø—Ä–∏—Ü–µ–ø–∞–º ‚Äî {today}</b>", ""]

    for i, it in enumerate(items, 1):
        title = esc_html(extract_title(it))
       url = with_utm(extract_url(it))


        meaning = meaning_for(extract_title(it))


        lines.append(f"{i}Ô∏è‚É£ <b>{title}</b>")
        lines.append(esc_html(meaning))
        lines.append(f"üîó {url}")
        lines.append("")

    lines.append("üìå –≠—Ç–æ –µ–∂–µ–¥–Ω–µ–≤–Ω–∞—è —Å–≤–æ–¥–∫–∞: –±–µ–∑ —Å–ø–∞–º–∞, —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω–æ–µ + –≤—ã–≤–æ–¥—ã.")
    return "\n".join(lines).strip()

def tg_send(text: str):
    if not BOT_TOKEN or not CHAT_ID:
        raise RuntimeError("Missing TELEGRAM_BOT_TOKEN or TELEGRAM_CHAT_ID")

    api = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": False,
    }
    r = requests.post(api, json=payload, timeout=30)

    # –ü–æ–∫–∞–∂–µ–º —Ç–µ–ª—É –æ—à–∏–±–∫–∏ Telegram (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ)
    try:
        j = r.json()
    except Exception:
        j = {"raw": r.text}

    print("Telegram status:", r.status_code)
    print("Telegram response:", j)

    r.raise_for_status()
    if not j.get("ok"):
        raise RuntimeError(f"Telegram API error: {j}")
        
def meaning_for(title: str) -> str:
    t = title.lower()

    # —Ü–µ–Ω—ã / —Ä—ã–Ω–æ–∫
    if any(k in t for k in ["–¥–µ—à–µ–≤", "–ø–æ–¥–æ—Ä–æ–∂", "—Ü–µ–Ω–∞", "—Å—Ç–æ–∏–º–æ—Å—Ç", "—Ä—ã–Ω–æ–∫", "–ø—Ä–æ–¥–∞–∂", "—Å–ø—Ä–æ—Å"]):
        return "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –≤–æ–∑–º–æ–∂–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω –Ω–∞ —Ç–µ—Ö–Ω–∏–∫—É –∏ –∑–∞–ø—á–∞—Å—Ç–∏. –ï—Å–ª–∏ –ø–ª–∞–Ω–∏—Ä—É–µ—à—å –ø–æ–∫—É–ø–∫—É/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ ‚Äî —Å—Ä–∞–≤–Ω–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ —Å—Ä–æ–∫–∏ –ø–æ—Å—Ç–∞–≤–æ–∫."

    # –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ / –∑–∞–≤–æ–¥ / –≤—ã–ø—É—Å–∫
    if any(k in t for k in ["–≤—ã–ø—É—Å–∫", "–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤", "–∑–∞–≤–æ–¥", "—Å–æ–∫—Ä–∞—Ç", "—Ä–æ—Å—Ç –≤—ã–ø—É—Å–∫", "—Å–µ—Ä–∏—è"]):
        return "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –º–æ–≥—É—Ç –º–µ–Ω—è—Ç—å—Å—è —Å—Ä–æ–∫–∏ –ø–æ—Å—Ç–∞–≤–æ–∫ –∏ –Ω–∞–ª–∏—á–∏–µ. –î–µ—Ä–∂–∏ –≤ —É–º–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∫–∞ –∏ –∑–∞–∫–∞–∑–æ–≤ –∑–∞—Ä–∞–Ω–µ–µ."

    # –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ / –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ / –≤—ã—Å—Ç–∞–≤–∫–∏
    if any(k in t for k in ["–ø—Ä–µ–¥—Å—Ç–∞–≤", "–ø—Ä–µ–∑–µ–Ω—Ç", "–Ω–æ–≤–∏–Ω–∫", "–º–æ–¥–µ–ª—å", "–≤—ã—Å—Ç–∞–≤–∫", "—Ñ–æ—Ä—É–º"]):
        return "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –ø–æ—è–≤–ª—è—é—Ç—Å—è –Ω–æ–≤—ã–µ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏ –∏ —Ä–µ—à–µ–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å, –µ—Å—Ç—å –ª–∏ —É –Ω–æ–≤–∏–Ω–∫–∏ –ø–ª—é—Å—ã –ø–æ –≥—Ä—É–∑–æ–ø–æ–¥—ä—ë–º–Ω–æ—Å—Ç–∏, —Å–µ—Ä–≤–∏—Å—É –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –≤–ª–∞–¥–µ–Ω–∏—è."

    # –Ω–æ—Ä–º–∞—Ç–∏–≤–∫–∞ / —à—Ç—Ä–∞—Ñ—ã / –∫–æ–Ω—Ç—Ä–æ–ª—å
    if any(k in t for k in ["—à—Ç—Ä–∞—Ñ", "–∫–æ–Ω—Ç—Ä–æ–ª—å", "–∏–Ω—Å–ø–µ–∫—Ü", "—Ç—Ä–µ–±–æ–≤–∞–Ω", "–∑–∞–∫–æ–Ω", "–ø—Ä–∞–≤–∏–ª", "—Å–µ—Ä—Ç–∏—Ñ"]):
        return "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –ø–æ–≤—ã—à–∞–µ—Ç—Å—è —Ä–∏—Å–∫ —à—Ç—Ä–∞—Ñ–æ–≤ –∏ –ø—Ä–æ—Å—Ç–æ–µ–≤. –ü—Ä–æ–≤–µ—Ä—å –¥–æ–∫—É–º–µ–Ω—Ç—ã, –∫—Ä–µ–ø—ë–∂, —Å–≤–µ—Ç/—Ä–∞–∑—ä—ë–º—ã –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —É–∑–ª–æ–≤ –ø–µ—Ä–µ–¥ —Ä–µ–π—Å–æ–º."

    # —Å–µ—Ä–≤–∏—Å / –ø–æ–ª–æ–º–∫–∏ / —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è
    if any(k in t for k in ["—Ä–µ–º–æ–Ω—Ç", "—Å–µ—Ä–≤–∏—Å", "–ø–æ–ª–æ–º–∫", "–Ω–µ–∏—Å–ø—Ä–∞–≤", "—Ç–æ—Ä–º–æ–∑", "–æ—Å—å", "–ø–æ–¥–≤–µ—Å–∫", "—à–∏–Ω—ã"]):
        return "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –æ–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ —É–∑–ª–æ–≤. –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–æ–±–ª–µ–º—ã –ª—É—á—à–µ –ª–æ–≤–∏—Ç—å –∑–∞—Ä–∞–Ω–µ–µ ‚Äî —ç—Ç–æ –¥–µ—à–µ–≤–ª–µ, —á–µ–º –ø—Ä–æ—Å—Ç–æ–π –Ω–∞ –ª–∏–Ω–∏–∏."

    # –¥–µ—Ñ–æ–ª—Ç
    return "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç: –¥–µ—Ä–∂–∏ –≤ —Ñ–æ–∫—É—Å–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—é, —Å—Ä–æ–∫–∏ –∏ –∑–∞—Ç—Ä–∞—Ç—ã. –°—Å—ã–ª–∫–∏ –∏ –¥–µ—Ç–∞–ª–∏ ‚Äî –Ω–∏–∂–µ."


def main():
    state = load_state()

    # –∑–∞—â–∏—Ç–∞ –æ—Ç –¥–≤–æ–π–Ω–æ–≥–æ –ø–æ—Å—Ç–∏–Ω–≥–∞ –≤ –æ–¥–∏–Ω –¥–µ–Ω—å (–µ—Å–ª–∏ workflow –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏–ª–∏)
    today = datetime.now().strftime("%Y-%m-%d")
    if state.get("last_post_date") == today:
        print("Digest already posted today. Exit.")
        return

    used = set(state.get("used_urls", []))
    news = read_news()
    picked = pick_items(news, used)
    if len(picked) < 3:
    print(f"Too few items for digest: {len(picked)}. Exit.")
    return

    if not picked:
        print("No suitable items found (topic/freshness/duplicates). Exit.")
        return

    post = make_digest_post(picked)
    tg_send(post)

    # –æ–±–Ω–æ–≤–ª—è–µ–º state: –∑–∞–ø–æ–º–∏–Ω–∞–µ–º —Å—Å—ã–ª–∫–∏, —á—Ç–æ–±—ã –∑–∞–≤—Ç—Ä–∞ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è
    for it in picked:
        url = extract_url(it)
        if url:
            used.add(url)

    state["used_urls"] = list(used)[-500:]  # –æ–≥—Ä–∞–Ω–∏—á–∏–º –ø–∞–º—è—Ç—å
    state["last_post_date"] = today
    save_state(state)

    print("OK: digest posted.")

if __name__ == "__main__":
    main()
